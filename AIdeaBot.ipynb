{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQT/QA+N41CkjQOtwo9zyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcioluiskroth/imersao_ai_alura/blob/main/AIdeaBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyg8qMtaakrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67ea1a5-bdbf-4f36-c46c-135ed3b1112a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, descreva a tarefa que você deseja que o chatbot execute. Você pode usar verbos como gere, crie, pesquise.\n"
          ]
        }
      ],
      "source": [
        "# Instala a biblioteca google-generativeai\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "# Importa a biblioteca e configura a chave API\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import random\n",
        "\n",
        "minha_api = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=minha_api)\n",
        "\n",
        "# Define o modelo de linguagem\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "def get_user_input(prompt, is_required=True):\n",
        "    user_input = input(prompt)\n",
        "    while is_required and user_input.strip() == \"\":\n",
        "        print(\"Este campo é obrigatório. Por favor, forneça uma resposta.\")\n",
        "        user_input = input(prompt)\n",
        "    return user_input\n",
        "\n",
        "def start_conversation():\n",
        "    action_verbs = [\"crie\", \"pesquise\", \"gere\", \"escreva\", \"analise\", \"apresente\", \"descreva\"]\n",
        "    print(f\"Por favor, descreva a tarefa que você deseja que o chatbot execute. Você pode usar verbos como {', '.join(random.sample(action_verbs, 3))}.\")\n",
        "    task = get_user_input(\"Tarefa a ser realizada pelo chatbot: \")\n",
        "\n",
        "    print(\"\\nExemplos de contextos: 1) Criar um resumo de um livro. 2) Pesquisar as últimas notícias sobre tecnologia. 3) Gerar um código para análise de dados.\")\n",
        "    context = get_user_input(\"Contexto relacionado à tarefa: \")\n",
        "\n",
        "    example_text = get_user_input(\"Texto de exemplo (opcional): \", is_required=False)\n",
        "\n",
        "    print(\"\\nComo o chatbot deve agir? Exemplos: 1) Como um assistente amigável. 2) Como um professor. 3) Como um consultor técnico.\")\n",
        "    persona = get_user_input(\"Como deve atuar o chatbot: \")\n",
        "\n",
        "    format = get_user_input(\"Formato do retorno (ex: tabela, texto, código), opcional: \", is_required=False)\n",
        "\n",
        "    print(\"\\nExemplos de tom: 1) Profissional. 2) Respeitoso. 3) Sarcástico.\")\n",
        "    humor = get_user_input(\"Tom da resposta (opcional): \")\n",
        "\n",
        "    preprompt = f\" Atue como {persona}, com um humor {humor}, {task}, no formato de {format}, dentro do seguinte contexto: {context}, {example_text}\"\n",
        "    return preprompt\n",
        "\n",
        "def confirm_prompt(preprompt):\n",
        "    print(f\"Acho que entendi o que você precisa que eu faça, seria isso? \\\"{preprompt}\\\"\")\n",
        "    while True:\n",
        "        user_choice = input(\"Posso continuar? [Sim/Não/Editar/Recomeçar]: \").lower()\n",
        "        if user_choice == \"sim\":\n",
        "            return True, preprompt\n",
        "        elif user_choice == \"não\":\n",
        "            return False, preprompt\n",
        "        elif user_choice == \"editar\":\n",
        "            edited_prompt = get_user_input(\"Edite a frase como desejar: \")\n",
        "            return True, edited_prompt\n",
        "        elif user_choice == \"recomeçar\":\n",
        "            return None, None\n",
        "\n",
        "def send_to_api(prompt):\n",
        "    try:\n",
        "        instruction = f\" {prompt}\"\n",
        "        chat = model.start_chat(history=[])\n",
        "        response = chat.send_message(instruction)\n",
        "        return response.text\n",
        "    except google.generativeai.StopCandidateException as e:\n",
        "        print(\"Desculpe, o conteúdo fornecido foi considerado inapropriado pela API. Por favor, reformule sua solicitação.\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        preprompt = start_conversation()\n",
        "        continuation, temp_prompt = confirm_prompt(preprompt)\n",
        "        if continuation is True:\n",
        "            final_response = send_to_api(temp_prompt)\n",
        "            if final_response:\n",
        "                print(f\"Resposta final: {final_response}\\n\\n\")\n",
        "                more = input(\"Algo mais? [Sim/Não]: \").lower()\n",
        "                if more == \"não\":\n",
        "                    break\n",
        "            else:\n",
        "                print(\"Vamos tentar novamente.\")\n",
        "                continue\n",
        "        elif continuation is False:\n",
        "            break\n",
        "        elif temp_prompt is None:\n",
        "            continue\n",
        "\n",
        "# Inicia a interação\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        ""
      ]
    }
  ]
}